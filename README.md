# BERT: Bidirectional Embedding Representations form Transformers
This is my implementation of Google AI's BERT model ([paper](https://arxiv.org/pdf/1810.04805.pdf)), with the use case of Question-Answering in mind. The official repository is [here](https://github.com/google-research/bert) - I intend to develop a better grasp of Tensorflow and the different practices of training LM's introduced in the paper.

No code is borrowed from the official BERT repository, but only its architecture and new training methods.